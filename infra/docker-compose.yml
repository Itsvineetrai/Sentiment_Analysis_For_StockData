version: '3.8'
services:
  zookeeper:
    image: 'confluentinc/cp-zookeeper:7.4.0'
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - '2181:2181'
  kafka:
    image: 'confluentinc/cp-kafka:7.4.0'
    depends_on:
      - zookeeper
    container_name: kafka 
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - '9092:9092'
      - '29092:29092'
  kafka-ui:
    image: 'provectuslabs/kafka-ui:latest'
    container_name: kafka-ui
    depends_on:
      - kafka
      - zookeeper
    ports:
      - '8080:8080'
    environment:
      KAFKA_CLUSTERS_0_NAME: 'local'
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 'kafka:9092'
      KAFKA_CLUSTERS_0_ZOOKEEPER: 'zookeeper:2181'

  spark-master:
    image: 'bitnami/spark:3.5.1'
    depends_on:
      - kafka
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - HOME=/tmp
    ports:
      - '8081:8080'  # Spark Master Web UI (mapped to 8081 outside to avoid conflict with Kafka-UI)
      - '7077:7077'  # Spark Master Port
    volumes:
      - ../week3-news/spark-streaming/src:/opt/bitnami/spark/app/
      - ../week4-social/Ticker:/data:ro


  
  spark-worker-1:
    image: 'bitnami/spark:3.5.1'
    depends_on:
      - spark-master
      - kafka
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4g
      - SPARK_WORKER_CORES=8
      - HOME=/tmp
    volumes:
      - ../week3-news/spark-streaming/src:/opt/bitnami/spark/app/
      - ../week4-social/Ticker:/data:ro

  spark-worker-2:
    image: 'bitnami/spark:3.5.1'
    depends_on:
      - spark-master
      - kafka
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4g
      - SPARK_WORKER_CORES=8
      - HOME=/tmp
    volumes:
      - ../week3-news/spark-streaming/src:/opt/bitnami/spark/app/
      - ../week4-social/Ticker:/data:ro

  news-producer:
    build: ../week3-news/news-producer
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - TICKERS_CSV=/data/tickers.csv
    volumes:
      - ../Ticker:/data:ro
    depends_on:
      - kafka

  social-analytics:
    build: ../week4-social/spark-analytics
    depends_on:
      - spark-master
      - kafka
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - TICKERS_CSV=/data/tickers.csv
    volumes:
      - ../week4-social/Ticker:/data:ro
    command: [
      "spark-submit",
      "--master", "spark://spark-master:7077",
      "--total-executor-cores", "2",
      "--executor-memory", "1g",
      "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1",
      "/opt/spark/app/src/social_analytics.py"
    ]